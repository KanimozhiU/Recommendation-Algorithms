{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_iJIZxBaDyW"
   },
   "source": [
    "# Brief \n",
    "\n",
    "Initially started by using a GRU RNN that consumed each of the prior months maintaining a context and final linear layer that took the user features along with the final hidden output. This required more validation due to more variables and due to time constraint I cut the losses and simply implemented a more basic gradient boosting version that does pretty good. We make the assumption that the predicted new produts at a given month are conditionally independent of all the months 5 months prior and more given the buying patterns for the past 4 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yB7bhVtSG7bI",
    "outputId": "8e2f6c6f-74ed-4959-9722-12a4a0d6113c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at drive\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import gc\n",
    "import xgboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUyLfTwiToH3"
   },
   "source": [
    "# Defining Features of Interest\n",
    "\n",
    "This section simply defines which temporal/user features will be used in the prediction along with which products we want to recommend. This is roughly the same as the landing page on the kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7tcv09GZXYa"
   },
   "outputs": [],
   "source": [
    "months = ['2015-01-28', '2015-02-28', '2015-03-28', '2015-04-28', '2015-05-28',\n",
    "         '2015-06-28', '2015-07-28', '2015-08-28', '2015-09-28', '2015-10-28',\n",
    "         '2015-11-28', '2015-12-28', '2016-01-28', '2016-02-28', '2016-03-28',\n",
    "         '2016-04-28', '2016-05-28'] # unique months whose data we have\n",
    "       \n",
    "products = ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1', \n",
    "            'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1', \n",
    "            'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1', \n",
    "            'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1', \n",
    "            'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "            'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "            'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "            'ind_nomina_ult1', 'ind_nom_pens_ult1',  'ind_recibo_ult1'] # all possible products available to buy\n",
    "        \n",
    "rec_products = ['ind_recibo_ult1', 'ind_cco_fin_ult1', 'ind_nom_pens_ult1',\n",
    "                'ind_nomina_ult1', 'ind_tjcr_fin_ult1', 'ind_ecue_fin_ult1',\n",
    "                'ind_cno_fin_ult1', 'ind_ctma_fin_ult1', 'ind_reca_fin_ult1',\n",
    "                'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1', 'ind_valo_fin_ult1'] # all products we hope to recommend\n",
    "    \n",
    "features = ['fecha_dato', 'ncodpers', 'ind_empleado', \n",
    "                'pais_residencia', 'sexo', 'age', 'fecha_alta', 'ind_nuevo', \n",
    "                'antiguedad', 'indrel', 'ult_fec_cli_1t', 'indrel_1mes',\n",
    "                'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada',\n",
    "                'indfall', 'tipodom', 'cod_prov', 'nomprov',\n",
    "                'ind_actividad_cliente', 'renta', 'segmento'] # user features provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvzIjNNIVUCy"
   },
   "source": [
    "# Functions for parsing and munging/wrangling the data\n",
    "\n",
    "These functions extract the data from the csv file and structure it so that a single instance has the inputs contain merged months of prior data into a single row. These are primarily for convenience and also do some small imputations such as that for missing rent values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4tXszq3ZjWz"
   },
   "outputs": [],
   "source": [
    "def get_data_by_month(dates, months, features, products):\n",
    "    ids = dates.index[dates.fecha_dato.isin(months)]\n",
    "    return pd.read_csv('drive/My Drive/santander-product-recommendation/train_ver2.csv', usecols=features + products, skiprows= range(1,ids[0]+1), nrows=len(ids), header=0)\n",
    "    \n",
    "def get_features(data, pdata):\n",
    "    data['isEmployed'] = data['ind_empleado'].map(lambda x: 0 if (x=='N' or x=='S') else 1)\n",
    "                    \n",
    "    if data.antiguedad.dtype != np.int64 and data.antiguedad.dtype != np.float64:\n",
    "        data['antiguedad'] = data.antiguedad.str.strip()\n",
    "        data['antiguedad'] = data.antiguedad.map(lambda x: None if x=='NA' else int(x))\n",
    "\n",
    "    data.antiguedad[data.antiguedad<0] = data.antiguedad.max()\n",
    "    data.antiguedad.fillna(data.antiguedad.median(), inplace=True)\n",
    "    \n",
    "    if data.age.dtype != np.int64 and data.age.dtype != np.float64:\n",
    "        data['age'] = data.age.str.strip()\n",
    "        data['age'] = data.age.map(lambda x: None if x=='NA' else int(x))\n",
    "\n",
    "    # fill missing values\n",
    "    data.age.fillna(data.age.median(), inplace=True)\n",
    "    data.tiprel_1mes.fillna('I', inplace=True)\n",
    "    data['sexo'] = data['sexo'].map(lambda x: x != 'H').astype(int)\n",
    "    data.segmento.fillna('02 - PARTICULARES', inplace=True)\n",
    "    data.segmento = data.segmento.map(lambda x: x[:2])\n",
    "    data.indfall.fillna('N', inplace=True)\n",
    "    data['indfall'] = data['indfall'].map(lambda x: x == 'S').astype(int)\n",
    "    \n",
    "    data.cod_prov.fillna(99, inplace=True) # Dummy State Code for Foreign clients\n",
    "    data['renta'] = pd.to_numeric(data['renta'], errors='coerce')\n",
    "    for seg in data.segmento.unique(): # segment\n",
    "        med = data[data.segmento==seg]['renta'].dropna().median()\n",
    "        data.loc[(data.renta.isnull()) & (data.segmento==seg), 'renta'] = med # impute median from this segment of society\n",
    "\n",
    "    Xclient = pd.concat([data[['ncodpers', 'isEmployed', 'sexo', 'age', 'antiguedad', 'indfall', 'ind_actividad_cliente', 'renta']], \n",
    "                        pd.get_dummies(data['tiprel_1mes'].apply(str)),\n",
    "                        pd.get_dummies(data['segmento'].apply(str))],\n",
    "                        axis=1)\n",
    "    del data # clean up to avoid memory issues\n",
    "    gc.collect()\n",
    "    X = pd.merge(Xclient, pdata, how='left', on='ncodpers') # combine per customer data\n",
    "    X.fillna(0, inplace=True)\n",
    "    return X\n",
    "    \n",
    "def get_new_products(data, pdata):\n",
    "    intsec = np.intersect1d(data.ncodpers, pdata.ncodpers) # only consider users with previous month and current month data\n",
    "    merged = pd.merge(data, pdata, how='left', on='ncodpers')\n",
    "    merged.fillna(0, inplace=True)\n",
    "    added = pd.DataFrame(merged.ncodpers)\n",
    "    for i, pr in enumerate(rec_products):\n",
    "        added[pr] = merged.loc[:, pr + '_x'] - merged.loc[:, pr + '_y']\n",
    "        added.loc[added[pr] == -1, pr] = 0\n",
    "    \n",
    "    return added.drop(['ncodpers'], axis=1)\n",
    "    \n",
    "def get_temp_features(merged, months):\n",
    "    for month in months:\n",
    "        temp_data = get_data_by_month(dates, [month], ['ncodpers'], products)\n",
    "        i = months.index(month)\n",
    "        merged = pd.merge(merged, temp_data, how='left', on='ncodpers', suffixes=[i, i+1])\n",
    "        merged.fillna(0, inplace=True)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDu6owHHaNtC"
   },
   "outputs": [],
   "source": [
    "dates = pd.read_csv('drive/My Drive/santander-product-recommendation/train_ver2.csv', usecols=['fecha_dato'], header=0)\n",
    "\n",
    "month = '2015-06-28' # '2016-05-28'\n",
    "pmonth = months[months.index(month) - 1]\n",
    "\n",
    "data = get_data_by_month(dates, [month], features, products)\n",
    "pdata = get_data_by_month(dates, [pmonth], ['ncodpers'], products)\n",
    "\n",
    "X = get_features(data[features], pdata)\n",
    "\n",
    "temp1 = months[months.index(pmonth) - 1]\n",
    "temp2 = months[months.index(temp1) - 1]\n",
    "temp3 = months[months.index(temp2) - 1]\n",
    "temp4 = months[months.index(temp3) - 1]\n",
    "target_months = [temp1, temp2, temp3, temp4]\n",
    "\n",
    "X = get_temp_features(X, target_months)\n",
    "X.drop(['ncodpers'], axis=1, inplace=True)\n",
    "\n",
    "y = get_new_products(data[['ncodpers']+products], pdata)\n",
    "\n",
    "del data, pdata\n",
    "\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.2, random_state=0)                                                      \n",
    "Xtrain = X\n",
    "ytrain = y\n",
    "\n",
    "del X, y\n",
    "gc.collect() # running into memory issues here so explicitly calling gc\n",
    "\n",
    "new_products = np.sum(ytrain, axis=1)\n",
    "Xtrain = Xtrain[new_products!=0]\n",
    "ytrain = ytrain[new_products!=0]\n",
    "\n",
    "targlist=[]\n",
    "for row in yval.values:\n",
    "    clientlist = []\n",
    "    for i in range(yval.shape[1]):\n",
    "        if row[i] == 1:\n",
    "            clientlist.append(rec_products[i])\n",
    "    targlist.append(clientlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7nfNTGAZ0Ku"
   },
   "source": [
    "# Training each of the Gradient Boosting Predictors\n",
    "\n",
    "We implement the XGBoost library that use on gradient boosting to make a predictor for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GUlcp49Yr2W"
   },
   "outputs": [],
   "source": [
    "clfdict = {} # train a decision tree per product\n",
    "probs = [] # predicted probabilities of products being purchased\n",
    "freq = ytrain.sum(axis=0) # \n",
    "for pr in rec_products:\n",
    "    clf = xgboost.XGBClassifier(max_depth=6, learning_rate = 0.08, subsample = 0.9, colsample_bytree = 0.9, n_estimators=100, base_score = freq[pr]/Xtrain.shape[0], nthread=4)\n",
    "    clfdict[pr] = clf\n",
    "    clf.fit(Xtrain, ytrain.loc[:, pr])\n",
    "    ypredv = clf.predict(Xval)\n",
    "    probs.append(clf.predict_proba(Xval)[:, 1])\n",
    "    \n",
    "probs = np.array(probs).T\n",
    "likeliestprods = np.argsort(probs, axis=1)[:, :-8:-1] # ids of seven greatest probs\n",
    "prlist = [[rec_products[j] for j in row] for row in likeliestprods]\n",
    "\n",
    "\n",
    "del Xtrain, Xval, ytrain, yval # avoid loading test and train in memory at same time\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLg_6l3fdgKr"
   },
   "outputs": [],
   "source": [
    "months = ['2015-01-28', '2015-02-28', '2015-03-28', '2015-04-28', '2015-05-28',\n",
    "         '2015-06-28', '2015-07-28', '2015-08-28', '2015-09-28', '2015-10-28',\n",
    "         '2015-11-28', '2015-12-28', '2016-01-28', '2016-02-28', '2016-03-28',\n",
    "         '2016-04-28', '2016-05-28'] # unique months whose data we have\n",
    "       \n",
    "products = ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1', \n",
    "            'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1', \n",
    "            'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1', \n",
    "            'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1', \n",
    "            'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "            'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "            'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "            'ind_nomina_ult1', 'ind_nom_pens_ult1',  'ind_recibo_ult1'] # all possible products available to buy\n",
    "        \n",
    "rec_products = ['ind_recibo_ult1', 'ind_cco_fin_ult1', 'ind_nom_pens_ult1',\n",
    "                'ind_nomina_ult1', 'ind_tjcr_fin_ult1', 'ind_ecue_fin_ult1',\n",
    "                'ind_cno_fin_ult1', 'ind_ctma_fin_ult1', 'ind_reca_fin_ult1',\n",
    "                'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1', 'ind_valo_fin_ult1'] # all products we hope to recommend\n",
    "    \n",
    "features = ['fecha_dato', 'ncodpers', 'ind_empleado', \n",
    "                'pais_residencia', 'sexo', 'age', 'fecha_alta', 'ind_nuevo', \n",
    "                'antiguedad', 'indrel', 'ult_fec_cli_1t', 'indrel_1mes',\n",
    "                'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada',\n",
    "                'indfall', 'tipodom', 'cod_prov', 'nomprov',\n",
    "                'ind_actividad_cliente', 'renta', 'segmento'] # user features provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIby1B_PZAz1"
   },
   "source": [
    "# Predictions\n",
    "\n",
    "Recommends 5 products per applicable customer in test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v7sbopNKZqgW",
    "outputId": "a89386f2-2733-43ef-c72f-d784f5aeb317"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "month = '2016-06-28'\n",
    "pmonth = '2016-05-28'\n",
    "\n",
    "data = pd.read_csv('drive/My Drive/santander-product-recommendation/test_ver2.csv', usecols=features, header=0)\n",
    "pdata = get_data_by_month(dates, [pmonth], ['ncodpers'], products)\n",
    "\n",
    "Xtest = get_features(data[features], pdata)\n",
    "\n",
    "temp1 = months[months.index(pmonth) - 1]\n",
    "temp2 = months[months.index(temp1) - 1]\n",
    "temp3 = months[months.index(temp2) - 1]\n",
    "temp4 = months[months.index(temp3) - 1]\n",
    "\n",
    "months = [temp1, temp2, temp3, temp4]\n",
    "Xtest = get_temp_features(Xtest, months)\n",
    "         \n",
    "ids = Xtest['ncodpers']\n",
    "Xtest.drop(['ncodpers'], axis=1, inplace=True)\n",
    "\n",
    "probs = []\n",
    "for pr in rec_products:\n",
    "    probs.append(clfdict[pr].predict_proba(Xtest)[:, 1])\n",
    "probs = np.array(probs).T\n",
    "        \n",
    "likeliestprods = np.argsort(probs, axis=1)[:, :-6:-1]\n",
    "test_preds = [[rec_products[j] for j in row] for row in likeliestprods] # recommend 5 likeliest products alternatively threshold on probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFDq9KpRhvQn"
   },
   "source": [
    "## Write predictions to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-av8tAafdPk"
   },
   "outputs": [],
   "source": [
    "out = pd.DataFrame()\n",
    "out['id'] = ids \n",
    "for i in range(5):\n",
    "    out['p' + str(i)] = np.array(test_preds)[:, i]\n",
    "out.to_csv('output.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "santander-pred.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
